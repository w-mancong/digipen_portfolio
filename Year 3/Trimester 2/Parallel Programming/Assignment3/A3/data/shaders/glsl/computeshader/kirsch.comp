#version 450

layout (local_size_x = 16, local_size_y = 16) in;
layout (binding = 0, rgba8) uniform readonly image2D inputImage;
layout (binding = 1, rgba8) uniform image2D resultImage;

const float kirsch[8][3][3] = 
{
    {
        {  5,  5,  5 },
        { -3,  0, -3 },     /*rotation 1 */
        { -3, -3, -3 }
    },
    {
        {  5,  5, -3 },
        {  5,  0, -3 },     /*rotation 2 */
        { -3, -3, -3 }
    },
    {
        { 5, -3, -3 },
        { 5,  0, -3 },      /*rotation 3 */
        { 5, -3, -3 }
    },
    {
        { -3, -3, -3 },
        { 5,  0,  -3 },     /*rotation 4 */
        { 5,  5,  -3 }
    },
    {
        { -3, -3, -3 },
        { -3,  0, -3 },     /*rotation 5 */
        {  5,  5,  5 }
    },
    {
        { -3, -3, -3 },
        { -3,  0,  5 },     /*rotation 6 */
        { -3,  5,  5 }
    },
    {
        { -3, -3, 5 },
        { -3,  0, 5 },      /*rotation 7 */
        { -3, -3, 5 }
    },
    {
        { -3 ,  5,  5 },
        { -3 ,  0,  5 },    /*rotation 8 */
        { -3 , -3, -3 }
    }
};

//two extra row/col
shared vec3 sData[16+2][16+2];

const int THREAD_SIZE = 16;
const int SHARED_MEMORY_SIZE = THREAD_SIZE + 2;

// Code is in row major
void main()
{
    // gl_WorkGroupSize == blockDim (in this case is 16)
    // blockIdx * blockDim + threadIdx == gl_GlobalInvocationID
    
    ivec2 threadIdx = ivec2(gl_LocalInvocationID.xy);
    ivec2 blockIdx  = ivec2(gl_WorkGroupID.xy);
    ivec2 blockDim  = ivec2(gl_WorkGroupSize.xy);

    const int TOTAL_ITERATIONS = int( ceil((SHARED_MEMORY_SIZE * SHARED_MEMORY_SIZE) / (THREAD_SIZE * THREAD_SIZE)) );

    for(int i = 0; i < TOTAL_ITERATIONS; ++i)
    {
        // Load into shared memory first

        
        int x = blockIdx.x * blockDim.x + threadIdx.x - 1;
        int y = blockIdx.y * blockDim.y + threadIdx.y - 1;

        
        
        // sData[0][0] = imageLoad(inputImage, ivec( blockIdx.x * blockDim.x (16) + threadIdx.x, blockIdx.y * blockDim.y (16) + threadIdx.y )).rgb; 
    }

    // Synchronize all threads in the work group
    groupMemoryBarrier();
    // perform convolution here
}
 	
 
 
 
